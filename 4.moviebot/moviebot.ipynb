{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# Replace 'YOUR_API_KEY' with your actual OpenAI API key\n",
        "import os\n",
        "os.environ['OPENAI_API_KEY'] = 'YOUR_API_KEY' #Sets your ‘OPENAI_API_KEY’ Environment Variable"
      ],
      "metadata": {
        "id": "ChHPFGzcP2G7"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install langchain"
      ],
      "metadata": {
        "id": "gvC3ot7ROaMv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install openai"
      ],
      "metadata": {
        "id": "pb_vOFtvPWpk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Using OpenAI LLM\n"
      ],
      "metadata": {
        "id": "T3aaAS1fjsYV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.llms import OpenAI #Importing the OpenAI LLM\n",
        "\n",
        "llm = OpenAI(temperature = 0.6)\n",
        "# creates an instance of the OpenAI language model. The temperature parameter is being set to 0.6,\n",
        "#which is a hyperparameter that controls the randomness of the model's output. Higher values (e.g., 1.0)\n",
        "#make the output more random, while lower values (e.g., 0.2) make it more deterministic\n",
        "\n",
        "name = llm(\"I want to make an Action movie. Suggest a catchy name for this.\")\n",
        "# OpenAI language model will use this prompt to generate a response"
      ],
      "metadata": {
        "id": "560OH-BvOgJ3"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(name)"
      ],
      "metadata": {
        "id": "Oz8OLnBGPlU1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Using LLM Chain with PromptTemplate"
      ],
      "metadata": {
        "id": "YTft4cq-jx93"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.prompts import PromptTemplate\n",
        "\n",
        "prompt_template_name = PromptTemplate(\n",
        "    input_variables = ['genre'], #prompt template expects a value for the 'genre' variable to be provided when creating a prompt.\n",
        "    template = \"I want to make a {genre} movie. Suggest a catchy name for this.\" #This is a string template for the prompt.\n",
        "    #The {genre} placeholder will be replaced with the actual value when the template is used.\n",
        ")\n",
        "\n",
        "prompt_template_name.format(genre = 'Action') #this generates the following specific prompt: \"I want to make an Action movie. Suggest a catchy name for this.\""
      ],
      "metadata": {
        "id": "uzTq-RYSPnyb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.chains import LLMChain\n",
        "\n",
        "chain = LLMChain(llm = llm, prompt = prompt_template_name)\n",
        "chain.run(\"Action\")\n",
        "\n",
        "# This chain combines the llm's capabilities with the structured prompt template\n",
        "# to generate a response based on the given input - \"Action\" movie."
      ],
      "metadata": {
        "id": "R1cBgfuBQbG3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Using Simple Sequential Chain with PromptTemplate"
      ],
      "metadata": {
        "id": "YTcURZR7j5vU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.llms import OpenAI #Importing the OpenAI LLM\n",
        "from langchain.prompts import PromptTemplate\n",
        "from langchain.chains import LLMChain\n",
        "\n",
        "\n",
        "llm = OpenAI(temperature = 0.6)\n",
        "\n",
        "prompt_template_name = PromptTemplate(\n",
        "    input_variables = ['genre'],\n",
        "    template = \"I want to make a {genre} movie. Suggest a catchy name for this.\"\n",
        ")\n",
        "\n",
        "movie_name_chain = LLMChain(llm = llm, prompt = prompt_template_name)\n",
        "# like before we are creating a chain to get the movie name\n",
        "\n",
        "prompt_template_name = PromptTemplate(\n",
        "    input_variables = ['movie_name'],\n",
        "    template = \"Suggest some actors for {movie_name}. Return it as a comma separated list.\"\n",
        ")\n",
        "\n",
        "movie_actors_chain = LLMChain(llm = llm, prompt = prompt_template_name)\n",
        "# creating a chain to get the movie actors"
      ],
      "metadata": {
        "id": "aSqT5lPrQ1xy"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.chains import SimpleSequentialChain\n",
        "\n",
        "chain = SimpleSequentialChain(chains = [movie_name_chain, movie_actors_chain])\n",
        "response = chain.run(\"Action\")\n",
        "\n",
        "# using SimpleSequentialChain we are adding all the chains and getting the response.\n",
        "# the output of movie_name_chain will be used as input to movie_actors_chain in a sequential manner.\n",
        "print(response)"
      ],
      "metadata": {
        "id": "jhrF5xkpRN-y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Using Sequential Chain with PromptTemplate"
      ],
      "metadata": {
        "id": "F_EA4b7wkAZ-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.llms import OpenAI #Importing the OpenAI LLM\n",
        "from langchain.prompts import PromptTemplate\n",
        "from langchain.chains import LLMChain\n",
        "\n",
        "\n",
        "llm = OpenAI(temperature = 0.6)\n",
        "\n",
        "prompt_template_name = PromptTemplate(\n",
        "    input_variables = ['genre'],\n",
        "    template = \"I want to make a {genre} movie. Suggest a catchy name for this.\"\n",
        ")\n",
        "\n",
        "movie_name_chain = LLMChain(llm = llm, prompt = prompt_template_name, output_key=\"movie_name\")\n",
        "\n",
        "prompt_template_name = PromptTemplate(\n",
        "    input_variables = ['movie_name'],\n",
        "    template = \"Suggest some actors for {movie_name}. Return it as a comma separated list.\"\n",
        ")\n",
        "\n",
        "movie_actors_chain = LLMChain(llm = llm, prompt = prompt_template_name, output_key = \"movie_actors\")\n",
        "\n",
        "prompt_template_name = PromptTemplate(\n",
        "    input_variables = ['movie_name'],\n",
        "    template = \"Write a small opening scene for this movie: {movie_name}.\"\n",
        ")\n",
        "\n",
        "movie_scene_chain = LLMChain(llm = llm, prompt = prompt_template_name, output_key = \"movie_scene\")\n",
        "# this code sets up two chains (movie_name_chain and movie_actors_chain) that use the same language model (llm)\n",
        "# but different prompt templates to first generate a catchy movie name based on a genre and then suggest actors\n",
        "# for that movie based on the generated movie name. The output_key is used to associate the output of each chain\n",
        "# with the appropriate variable, either \"movie_name\" or \"movie_actors.\""
      ],
      "metadata": {
        "id": "RjeYkfp4SPib"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.chains import SequentialChain\n",
        "\n",
        "chain = SequentialChain(\n",
        "    chains = [movie_name_chain, movie_actors_chain, movie_scene_chain],\n",
        "    input_variables = ['genre'],\n",
        "    output_variables = ['movie_name', 'movie_actors', 'movie_scene']\n",
        ")\n",
        "\n",
        "movie_info = chain({'genre':'Action'})\n",
        "\n",
        "# this code sets up a sequential chain of language model operations using the SequentialChain class.\n",
        "# It combines two sub-chains (movie_name_chain and movie_actors_chain) into a sequence,\n",
        "# specifies input and output variables for the entire chain, and then runs the chain with input data\n",
        "# related to a movie's genre ('Action' in this case). The result, stored in movie_info, contains information about the movie's name and suggested actors.\n"
      ],
      "metadata": {
        "id": "sRghZRjrSuA0"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(movie_info)"
      ],
      "metadata": {
        "id": "a30NMcFfVRz5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "movie_name = movie_info['movie_name'].strip()\n",
        "movie_actors_str = movie_info['movie_actors'].strip()\n",
        "movie_actors = [actor.strip() for actor in movie_actors_str.split(',')]\n",
        "movie_scene = movie_info['movie_scene'].strip()"
      ],
      "metadata": {
        "id": "0oRa_l1sTdtT"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(movie_name)"
      ],
      "metadata": {
        "id": "XYQ9nf8DVhqX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(movie_actors)"
      ],
      "metadata": {
        "id": "h2GXSH_9VpYu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(movie_scene)"
      ],
      "metadata": {
        "id": "bDgUMALYtcrr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Searching Wikipedia"
      ],
      "metadata": {
        "id": "zsNyKdvIrY-k"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install wikipedia"
      ],
      "metadata": {
        "id": "RLWGSyxdV2mF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.document_loaders import WikipediaLoader"
      ],
      "metadata": {
        "id": "lSJFjMxsWSU_"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "docs = WikipediaLoader(query=movie_actors[0], load_max_docs=2).load()\n",
        "\n",
        "# fetches information from Wikipedia about a specific movie actor.\n",
        "# It queries Wikipedia with the actor's name (retrieved from movie_actors[0]) and limits the retrieval to a maximum of 2 documents.\n",
        "# The retrieved data is then stored in the variable docs - docs[0] and docs[1]\n"
      ],
      "metadata": {
        "id": "s5bNurwrWW1g"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "docs[0].page_content"
      ],
      "metadata": {
        "id": "TcGJcSv1WmTb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "docs[1].page_content"
      ],
      "metadata": {
        "id": "9XCuGyEKW1HF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Extracting Information from Wikipedia Documents"
      ],
      "metadata": {
        "id": "G5zTxsEbrg4Y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.chat_models import ChatOpenAI\n",
        "from langchain.chains import create_extraction_chain # using create_extraction_chain to extract specific information from text data.\n",
        "\n",
        "# define a schema, which is a structured way to specify the properties or pieces of information you want to extract from text data.\n",
        "schema = {\n",
        "    \"properties\": {\n",
        "        \"name\": {\"type\": \"string\"},\n",
        "        \"birth_date\": {\"type\": \"string\"},\n",
        "        \"movie_names\": {\"type\": \"string\"},\n",
        "    },\n",
        "}"
      ],
      "metadata": {
        "id": "A2M9cQFNxoMn"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# text data from where to extract\n",
        "inp = docs[0].page_content"
      ],
      "metadata": {
        "id": "R2BcCXRjx0ao"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Run chain\n",
        "llm = ChatOpenAI(temperature=0, model=\"gpt-3.5-turbo\")\n",
        "chain = create_extraction_chain(schema, llm)\n",
        "result = chain.run(inp)\n",
        "\n",
        "# Gives the result containing the extracted information structured according to the schema."
      ],
      "metadata": {
        "id": "luPHZIYXx1xd"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(result)"
      ],
      "metadata": {
        "id": "exgIkJUUyRlf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "actor_name = result[0]['name'].strip()\n",
        "actor_birth_date = result[0]['birth_date'].strip()\n",
        "actor_movies = result[0]['movie_names'].strip()\n",
        "actor_movies = [movie.strip() for movie in actor_movies.split(',')]"
      ],
      "metadata": {
        "id": "0E1hJKPJ0Bi0"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(actor_movies)"
      ],
      "metadata": {
        "id": "HEbeD8Tk0qNW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import openai"
      ],
      "metadata": {
        "id": "9qW98_3inrJe"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text = docs[0].page_content\n",
        "Query = \"Name the awards this person has received.\"\n",
        "\n",
        "def answer_query(text, query):\n",
        "  prompt = f\"{text}. Using the above text as context, answer this query:{Query}\"\n",
        "\n",
        "  # Call the OpenAI API to answer our query\n",
        "  response = openai.Completion.create(\n",
        "          engine=\"text-davinci-003\",\n",
        "          prompt=prompt,\n",
        "          max_tokens=256, # Set the maximum number of tokens for the summary, You can adjust this value based on your desired output length\n",
        "          temperature=0.1 # can adjust this value in range [0-1]; controls the diversity of the generated responses.\n",
        "          # Lower temperatures result in more predictable responses, while higher temperatures result in more variable responses.\n",
        "      )\n",
        "\n",
        "  # Extract and print the generated result\n",
        "  result = response.choices[0].text.strip()\n",
        "  return result"
      ],
      "metadata": {
        "id": "OzoGfNnllmlg"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(answer_query(text, Query))"
      ],
      "metadata": {
        "id": "-rvm9nmJoF4j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Replace 'YOUR_API_KEY' with your actual OpenAI API key\n",
        "\n",
        "openai.api_key = 'YOUR_API_KEY'"
      ],
      "metadata": {
        "id": "nY9FpwkRXko-"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Generating a Movie Poster"
      ],
      "metadata": {
        "id": "gtKSqGJ_kHag"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(movie_scene)"
      ],
      "metadata": {
        "id": "-P93ZFBz1PxT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_image(movie_scene):\n",
        "  prompt = f\"A digital art that depicts the scene: {movie_scene}\"\n",
        "  response = openai.Image.create(\n",
        "    prompt=prompt,\n",
        "    n=1\n",
        "  )\n",
        "  image = response[\"data\"][0][\"url\"]\n",
        "  return image\n",
        "\n",
        "# this code defines a function that generates a movie poster image based on a movie name using the OpenAI API.\n",
        "# The function takes the movie name as input, formats a prompt, sends it to the API to generate the image, and returns the URL of the generated image in the 'image' variable.\n",
        "\n",
        "image = generate_image(movie_scene)\n",
        "# our case - The sun was beginning to set on the horizon, casting an orange glow over the deserted cityscape.\n",
        "# In the center of the city, two figures stood facing each other, their silhouettes illuminated by the fading light.\n",
        "# The tension between them was palpable, and the air was thick with anticipation. Suddenly, a loud bell rang out, signaling the start of the ultimate showdown.\n"
      ],
      "metadata": {
        "id": "_T5Adk13W5w0"
      },
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(image)"
      ],
      "metadata": {
        "id": "VXaeVi_7XEjt"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}